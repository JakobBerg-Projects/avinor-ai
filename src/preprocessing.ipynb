{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e03d5c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c52389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "no_holidays = holidays.NO()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28e9c7",
   "metadata": {},
   "source": [
    "# Parametre & stier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d88b899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/raw_data/historical_flights.csv\"\n",
    "PREDICTION_PATH=\"../data/raw_data/scheduled_october2025.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775cdaa0",
   "metadata": {},
   "source": [
    "# Hjelpefunksjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d761742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flights(path: str, prediction: bool) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    if prediction:\n",
    "        for col in [\"std\", \"sta\"]:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "    else:\n",
    "        for col in [\"std\", \"sta\", \"atd\", \"ata\"]:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def handle_wrong_times(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    n0 = len(df)\n",
    "\n",
    "    # 1) Planlagt varighet\n",
    "    df['duration'] = df['sta'] - df['std']\n",
    "    df1 = df[(df['duration'] >= pd.Timedelta(0)) &\n",
    "             (df['duration'] <= pd.Timedelta(hours=10))].copy()\n",
    "    n1 = len(df1)\n",
    "\n",
    "    # 2) Ekstremt tidlige avvik (delay < -500 min)\n",
    "    dep_too_early = df1[\"atd\"].notna() & ((df1[\"atd\"] - df1[\"std\"]) < pd.Timedelta(minutes=-500))\n",
    "    arr_too_early = df1[\"ata\"].notna() & ((df1[\"ata\"] - df1[\"sta\"]) < pd.Timedelta(minutes=-500))\n",
    "    df2 = df1.loc[~(dep_too_early | arr_too_early)].copy()\n",
    "    n2 = len(df2)\n",
    "\n",
    "    print(f\"Totalt: {n0}\")\n",
    "    print(f\"  Fjernet på varighet: {n0 - n1}\")\n",
    "    print(f\"  Fjernet på ekstremt tidlig dep/arr: {n1 - n2}\")\n",
    "    print(f\"Beholdt: {n2}\")\n",
    "\n",
    "    return df2\n",
    "\n",
    "def build_full_grid(df: pd.DataFrame, prediction:bool) -> pd.DataFrame:\n",
    "    groups = pd.concat([df[\"dep_airport_group\"], df[\"arr_airport_group\"]]).dropna().unique()\n",
    "    if prediction:\n",
    "        tmin = pd.to_datetime(df[[\"std\",\"sta\"]].min(numeric_only=False).min()).floor(\"h\")\n",
    "        tmax = pd.to_datetime(df[[\"std\",\"sta\"]].max(numeric_only=False).max()).ceil(\"h\")\n",
    "    else:\n",
    "        tmin = pd.to_datetime(df[[\"std\",\"sta\",\"atd\",\"ata\"]].min(numeric_only=False).min()).floor(\"h\")\n",
    "        tmax = pd.to_datetime(df[[\"std\",\"sta\",\"atd\",\"ata\"]].max(numeric_only=False).max()).ceil(\"h\")\n",
    "    all_hours = pd.date_range(tmin, tmax, freq=\"h\")\n",
    "    return pd.MultiIndex.from_product([groups, all_hours], names=[\"airport_group\",\"timestamp\"]).to_frame(index=False)\n",
    "\n",
    "\n",
    "def make_intervals(df: pd.DataFrame, actual: bool = True) -> pd.DataFrame:\n",
    "\n",
    "    if actual:\n",
    "        dep = df.dropna(subset=[\"atd\"]).copy()\n",
    "        dep[\"start\"] = dep[\"atd\"] - pd.to_timedelta(15, \"m\")\n",
    "        dep[\"end\"]   = dep[\"atd\"] + pd.to_timedelta(8, \"m\")\n",
    "\n",
    "\n",
    "        arr = df.dropna(subset=[\"ata\"]).copy()\n",
    "        arr[\"start\"] = arr[\"ata\"] - pd.to_timedelta(16, \"m\")\n",
    "        arr[\"end\"]   = arr[\"ata\"] + pd.to_timedelta(5, \"m\")\n",
    "\n",
    "\n",
    "    else:\n",
    "        dep = df.dropna(subset=[\"std\"]).copy()\n",
    "        dep[\"start\"] = dep[\"std\"] - pd.to_timedelta(15, \"m\")\n",
    "        dep[\"end\"]   = dep[\"std\"] + pd.to_timedelta(8, \"m\")\n",
    "\n",
    "        arr = df.dropna(subset=[\"sta\"]).copy()\n",
    "        arr[\"start\"] = arr[\"sta\"] - pd.to_timedelta(16, \"m\")\n",
    "        arr[\"end\"]   = arr[\"sta\"] + pd.to_timedelta(5, \"m\")\n",
    "\n",
    "\n",
    "    dep[\"airport_group\"] = dep[\"dep_airport_group\"]\n",
    "    dep[\"type\"] = \"departure\"\n",
    "    arr[\"airport_group\"] = arr[\"arr_airport_group\"]\n",
    "    arr[\"type\"] = \"arrival\"\n",
    "\n",
    "    intervals = pd.concat([dep, arr], ignore_index=True)\n",
    "    intervals = intervals.dropna(subset=[\"airport_group\"])\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def expand_to_hours(intervals: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, row in intervals.iterrows():\n",
    "        hour_start = row[\"start\"].floor(\"h\")\n",
    "        hour_end = row[\"end\"].floor(\"h\")\n",
    "        hours = pd.date_range(hour_start, hour_end, freq=\"h\")\n",
    "        for h in hours:\n",
    "            rows.append({**row, \"timestamp\": h})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def hourly_overlap_group(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    hour = group[\"timestamp\"].iloc[0]\n",
    "    airport = group[\"airport_group\"].iloc[0]\n",
    "    events = []\n",
    "    for _, row in group.iterrows():\n",
    "        events.append((row[\"start\"], +1))\n",
    "        events.append((row[\"end\"], -1))\n",
    "    events.sort()\n",
    "    active, overlap = 0, 0\n",
    "    for _, change in events:\n",
    "        active += change\n",
    "        if active > 1:\n",
    "            overlap = 1\n",
    "            break\n",
    "    return pd.DataFrame([{\"airport_group\": airport, \"timestamp\": hour, \"target\": overlap}])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_hourly_features_from(intervals_any: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Feature-aggregater, men generisk (kan bruke actual ELLER scheduled intervaller).\n",
    "    \"\"\"\n",
    "    df = intervals_any.copy()\n",
    "    df[\"duration_min\"] = ((df[\"sta\"] - df[\"std\"]).dt.total_seconds() / 60)\n",
    "    \n",
    "    if \"flight_id\" in df:\n",
    "        df[\"airline\"] = df[\"flight_id\"].astype(str).str.extract(r\"^([A-Za-z]+)\")\n",
    "    df[\"airline\"] = \"\"\n",
    "\n",
    "    feats = df.groupby([\"airport_group\", \"timestamp\"]).agg(\n",
    "        flights_cnt     = (\"flight_id\", \"count\"),\n",
    "        avg_duration    = (\"duration_min\", \"mean\"),\n",
    "        max_duration    = (\"duration_min\", \"max\"),\n",
    "        passenger_share = (\"service_type\", lambda x: (x == \"J\").mean()),\n",
    "        cargo_share     = (\"service_type\", lambda x: (x == \"P\").mean()),\n",
    "        charter_share   = (\"service_type\", lambda x: (x == \"C\").mean()),\n",
    "        airline = (\"airline\", lambda x: x.mode().iloc[0] if not x.mode().empty else \"\")\n",
    "    ).reset_index()\n",
    "\n",
    "    return feats\n",
    "def add_time_features(feats: pd.DataFrame) -> pd.DataFrame:\n",
    "    feats[\"dow\"]     = feats[\"timestamp\"].dt.dayofweek\n",
    "    feats[\"holiday\"] = feats[\"timestamp\"].apply(lambda x: x.date() in no_holidays)\n",
    "    feats[\"month\"]   = feats[\"timestamp\"].dt.month\n",
    "    feats[\"hournum\"] = feats[\"timestamp\"].dt.hour\n",
    "    feats[\"weekend\"] = (feats[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    feats[\"date\"] = feats[\"timestamp\"].dt.normalize()\n",
    "\n",
    "    feats[\"daily_flights_cnt\"] = feats.groupby(\n",
    "        [\"airport_group\", \"date\"]\n",
    "    )[\"flights_cnt\"].transform(\"sum\")\n",
    "\n",
    "    feats = feats.sort_values([\"airport_group\", \"timestamp\"])\n",
    "    \n",
    "    return feats\n",
    "\n",
    "def add_prev_next(feats: pd.DataFrame) -> pd.DataFrame:\n",
    "    feats = feats.sort_values([\"airport_group\", \"timestamp\"])\n",
    "    feats[\"flights_cnt_prev\"] = feats.groupby(\"airport_group\")[\"flights_cnt\"].shift(1)\n",
    "    feats[\"flights_cnt_next\"] = feats.groupby(\"airport_group\")[\"flights_cnt\"].shift(-1)\n",
    "    feats[[\"flights_cnt_prev\", \"flights_cnt_next\"]] = feats[[\"flights_cnt_prev\", \"flights_cnt_next\"]].fillna(0).astype(int)\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bbc7c",
   "metadata": {},
   "source": [
    "# Last rådata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d4c8c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_id</th>\n",
       "      <th>dep_airport</th>\n",
       "      <th>dep_airport_group</th>\n",
       "      <th>arr_airport</th>\n",
       "      <th>arr_airport_group</th>\n",
       "      <th>service_type</th>\n",
       "      <th>std</th>\n",
       "      <th>sta</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>atd</th>\n",
       "      <th>ata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WF149</td>\n",
       "      <td>HOV</td>\n",
       "      <td>B</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-01-02 16:40:00</td>\n",
       "      <td>2018-01-02 17:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-01-02 18:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WF722</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MJF</td>\n",
       "      <td>D</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-01-28 13:04:00</td>\n",
       "      <td>2018-01-28 14:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WF188</td>\n",
       "      <td>FDE</td>\n",
       "      <td>A</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-04-07 07:10:00</td>\n",
       "      <td>2018-04-07 08:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-04-07 07:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WF176</td>\n",
       "      <td>HOV</td>\n",
       "      <td>B</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-04-07 11:00:00</td>\n",
       "      <td>2018-04-07 12:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-04-07 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WF148</td>\n",
       "      <td>HOV</td>\n",
       "      <td>B</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-04-30 08:25:00</td>\n",
       "      <td>2018-04-30 09:26:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-04-30 09:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410437</th>\n",
       "      <td>WF153</td>\n",
       "      <td>SOG</td>\n",
       "      <td>A</td>\n",
       "      <td>HOV</td>\n",
       "      <td>B</td>\n",
       "      <td>J</td>\n",
       "      <td>2025-05-03 09:25:00</td>\n",
       "      <td>2025-05-03 10:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-03 09:47:00</td>\n",
       "      <td>2025-05-03 10:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410438</th>\n",
       "      <td>WF153</td>\n",
       "      <td>BGO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOG</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>2025-05-03 08:35:00</td>\n",
       "      <td>2025-05-03 09:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-03 08:29:00</td>\n",
       "      <td>2025-05-03 09:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410439</th>\n",
       "      <td>WF158</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOV</td>\n",
       "      <td>B</td>\n",
       "      <td>J</td>\n",
       "      <td>2025-05-03 14:40:00</td>\n",
       "      <td>2025-05-03 15:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-03 14:35:00</td>\n",
       "      <td>2025-05-03 15:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410440</th>\n",
       "      <td>WF721</td>\n",
       "      <td>SSJ</td>\n",
       "      <td>D</td>\n",
       "      <td>TRD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>2025-05-03 08:50:00</td>\n",
       "      <td>2025-05-03 09:45:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-03 08:49:00</td>\n",
       "      <td>2025-05-03 09:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410441</th>\n",
       "      <td>WF182</td>\n",
       "      <td>FDE</td>\n",
       "      <td>A</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>2025-05-03 05:10:00</td>\n",
       "      <td>2025-05-03 06:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-03 05:08:00</td>\n",
       "      <td>2025-05-03 06:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410442 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       flight_id dep_airport dep_airport_group arr_airport arr_airport_group  \\\n",
       "0          WF149         HOV                 B         OSL               NaN   \n",
       "1          WF722         OSL               NaN         MJF                 D   \n",
       "2          WF188         FDE                 A         OSL               NaN   \n",
       "3          WF176         HOV                 B         OSL               NaN   \n",
       "4          WF148         HOV                 B         OSL               NaN   \n",
       "...          ...         ...               ...         ...               ...   \n",
       "410437     WF153         SOG                 A         HOV                 B   \n",
       "410438     WF153         BGO               NaN         SOG                 A   \n",
       "410439     WF158         OSL               NaN         HOV                 B   \n",
       "410440     WF721         SSJ                 D         TRD               NaN   \n",
       "410441     WF182         FDE                 A         OSL               NaN   \n",
       "\n",
       "       service_type                 std                 sta  cancelled  \\\n",
       "0                 J 2018-01-02 16:40:00 2018-01-02 17:15:00          0   \n",
       "1                 J 2018-01-28 13:04:00 2018-01-28 14:50:00          0   \n",
       "2                 J 2018-04-07 07:10:00 2018-04-07 08:10:00          0   \n",
       "3                 J 2018-04-07 11:00:00 2018-04-07 12:05:00          0   \n",
       "4                 J 2018-04-30 08:25:00 2018-04-30 09:26:00          0   \n",
       "...             ...                 ...                 ...        ...   \n",
       "410437            J 2025-05-03 09:25:00 2025-05-03 10:00:00          0   \n",
       "410438            J 2025-05-03 08:35:00 2025-05-03 09:10:00          0   \n",
       "410439            J 2025-05-03 14:40:00 2025-05-03 15:50:00          0   \n",
       "410440            J 2025-05-03 08:50:00 2025-05-03 09:45:00          0   \n",
       "410441            J 2025-05-03 05:10:00 2025-05-03 06:15:00          0   \n",
       "\n",
       "                       atd                 ata  \n",
       "0                      NaT 2018-01-02 18:53:00  \n",
       "1                      NaT                 NaT  \n",
       "2                      NaT 2018-04-07 07:55:00  \n",
       "3                      NaT 2018-04-07 12:00:00  \n",
       "4                      NaT 2018-04-30 09:36:00  \n",
       "...                    ...                 ...  \n",
       "410437 2025-05-03 09:47:00 2025-05-03 10:19:00  \n",
       "410438 2025-05-03 08:29:00 2025-05-03 09:18:00  \n",
       "410439 2025-05-03 14:35:00 2025-05-03 15:39:00  \n",
       "410440 2025-05-03 08:49:00 2025-05-03 09:39:00  \n",
       "410441 2025-05-03 05:08:00 2025-05-03 06:00:00  \n",
       "\n",
       "[410442 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = load_flights(DATA_PATH, prediction=False)\n",
    "df_pred = load_flights(PREDICTION_PATH, prediction=True)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348ce544",
   "metadata": {},
   "source": [
    "# Rens og filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f02755bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totalt: 410442\n",
      "  Fjernet på varighet: 86\n",
      "  Fjernet på ekstremt tidlig dep/arr: 97\n",
      "Beholdt: 410259\n"
     ]
    }
   ],
   "source": [
    "df = handle_wrong_times(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f25d5d",
   "metadata": {},
   "source": [
    "# Bygger full grid for alle timer i intervallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fc7f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = build_full_grid(df, prediction=False)\n",
    "grid_pred=build_full_grid(df_pred, prediction=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5873f406",
   "metadata": {},
   "source": [
    "# Intervaller (actual) + hourly overlap (actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4cd48b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9590/1819245093.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(hourly_overlap_group)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport_group</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>target_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-01-01 12:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-01-01 13:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-01-01 14:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-01-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-01-01 17:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airport_group           timestamp  target_actual\n",
       "0             A 2018-01-01 12:00:00              0\n",
       "0             A 2018-01-01 13:00:00              1\n",
       "0             A 2018-01-01 14:00:00              0\n",
       "0             A 2018-01-01 16:00:00              1\n",
       "0             A 2018-01-01 17:00:00              1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals_actual = make_intervals(df, actual=True)\n",
    "intervals_actual_expanded = expand_to_hours(intervals_actual)\n",
    "\n",
    "\n",
    "hourly_actual = (\n",
    "    intervals_actual_expanded\n",
    "    .groupby([\"airport_group\", \"timestamp\"], group_keys=False)\n",
    "    .apply(hourly_overlap_group)\n",
    "    .rename(columns={\"target\": \"target_actual\"})\n",
    ")\n",
    "\n",
    "hourly_actual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796bc6bc",
   "metadata": {},
   "source": [
    "# Intervaller (scheduled) + hourly overlap (scheduled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bece8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9590/3526365751.py:7: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(hourly_overlap_group)\n"
     ]
    }
   ],
   "source": [
    "intervals_sched = make_intervals(df, actual=False)\n",
    "intervals_sched_expanded = expand_to_hours(intervals_sched)\n",
    "\n",
    "hourly_sched = (\n",
    "    intervals_sched_expanded\n",
    "    .groupby([\"airport_group\", \"timestamp\"], group_keys=False)\n",
    "    .apply(hourly_overlap_group)\n",
    "    .rename(columns={\"target\": \"target_sched\"})\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa52cd",
   "metadata": {},
   "source": [
    "# Prediction Data Intervaller (scheduled) + hourly overlap (scheduled) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc4c34a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9590/2247729525.py:7: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(hourly_overlap_group)\n"
     ]
    }
   ],
   "source": [
    "intervals_pred = make_intervals(df_pred, actual=False)\n",
    "intervals_pred_expanded = expand_to_hours(intervals_pred)\n",
    "\n",
    "hourly_pred=(\n",
    "    intervals_pred_expanded\n",
    "    .groupby([\"airport_group\", \"timestamp\"], group_keys=False)\n",
    "    .apply(hourly_overlap_group)\n",
    "    .rename(columns={\"target\": \"target_sched\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2d5dd",
   "metadata": {},
   "source": [
    "# Merge targets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07f8e67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport_group</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>target_actual</th>\n",
       "      <th>target_sched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>2018-01-01 07:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>2018-01-01 09:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>2018-01-01 10:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>2018-01-01 11:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airport_group           timestamp  target_actual  target_sched\n",
       "0             B 2018-01-01 07:00:00              0             0\n",
       "1             B 2018-01-01 08:00:00              0             0\n",
       "2             B 2018-01-01 09:00:00              0             0\n",
       "3             B 2018-01-01 10:00:00              0             1\n",
       "4             B 2018-01-01 11:00:00              1             1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly = (grid\n",
    "          .merge(hourly_actual, on=[\"airport_group\",\"timestamp\"], how=\"left\")\n",
    "          .merge(hourly_sched,  on=[\"airport_group\",\"timestamp\"], how=\"left\"))\n",
    "hourly[[\"target_actual\",\"target_sched\"]] = hourly[[\"target_actual\",\"target_sched\"]].fillna(0).astype(int)\n",
    "hourly.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa66744",
   "metadata": {},
   "source": [
    "# Merge targets prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b6ba346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport_group</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>target_sched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G</td>\n",
       "      <td>2025-10-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>2025-10-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>2025-10-01 05:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G</td>\n",
       "      <td>2025-10-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2025-10-01 07:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airport_group           timestamp  target_sched\n",
       "0             G 2025-10-01 03:00:00             1\n",
       "1             G 2025-10-01 04:00:00             0\n",
       "2             G 2025-10-01 05:00:00             0\n",
       "3             G 2025-10-01 06:00:00             1\n",
       "4             G 2025-10-01 07:00:00             0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_pred=grid_pred.merge(hourly_pred, on=[\"airport_group\",\"timestamp\"], how=\"left\")\n",
    "hourly_pred[[\"target_sched\"]] = hourly_pred[[\"target_sched\"]].fillna(0).astype(int)\n",
    "hourly_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa986abf",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b794ae0e",
   "metadata": {},
   "source": [
    "# Feature-agg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec75601d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport_group</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>flights_cnt</th>\n",
       "      <th>avg_duration</th>\n",
       "      <th>max_duration</th>\n",
       "      <th>passenger_share</th>\n",
       "      <th>cargo_share</th>\n",
       "      <th>charter_share</th>\n",
       "      <th>airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-01-01 11:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-01-01 12:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-01-01 15:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-01-01 16:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-01-01 17:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airport_group           timestamp  flights_cnt  avg_duration  max_duration  \\\n",
       "0             A 2018-01-01 11:00:00            3     56.666667          60.0   \n",
       "1             A 2018-01-01 12:00:00            3     46.666667          60.0   \n",
       "2             A 2018-01-01 15:00:00            2     60.000000          60.0   \n",
       "3             A 2018-01-01 16:00:00            4     46.250000          65.0   \n",
       "4             A 2018-01-01 17:00:00            4     42.500000          60.0   \n",
       "\n",
       "   passenger_share  cargo_share  charter_share airline  \n",
       "0              1.0          0.0            0.0          \n",
       "1              1.0          0.0            0.0          \n",
       "2              1.0          0.0            0.0          \n",
       "3              1.0          0.0            0.0          \n",
       "4              1.0          0.0            0.0          "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_raw = make_hourly_features_from(intervals_sched_expanded.copy())\n",
    "feat_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b2cb32",
   "metadata": {},
   "source": [
    "# Feature-agg pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d25fdbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport_group</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>flights_cnt</th>\n",
       "      <th>avg_duration</th>\n",
       "      <th>max_duration</th>\n",
       "      <th>passenger_share</th>\n",
       "      <th>cargo_share</th>\n",
       "      <th>charter_share</th>\n",
       "      <th>airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-10-01 03:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-10-01 04:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>40.833333</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-10-01 06:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-10-01 07:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2025-10-01 08:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airport_group           timestamp  flights_cnt  avg_duration  max_duration  \\\n",
       "0             A 2025-10-01 03:00:00            2     47.500000          65.0   \n",
       "1             A 2025-10-01 04:00:00            6     40.833333          65.0   \n",
       "2             A 2025-10-01 06:00:00            3     51.666667          65.0   \n",
       "3             A 2025-10-01 07:00:00            6     41.666667          65.0   \n",
       "4             A 2025-10-01 08:00:00            2     47.500000          65.0   \n",
       "\n",
       "   passenger_share  cargo_share  charter_share airline  \n",
       "0              1.0          0.0            0.0          \n",
       "1              1.0          0.0            0.0          \n",
       "2              1.0          0.0            0.0          \n",
       "3              1.0          0.0            0.0          \n",
       "4              1.0          0.0            0.0          "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_pred_raw = make_hourly_features_from(intervals_pred_expanded.copy())\n",
    "feat_pred_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86863108",
   "metadata": {},
   "source": [
    "## Merger med full grid for alle timer og fyller inn verdier for timer der det ikke er noen fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f58a7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_full = grid.merge(feat_raw, on=[\"airport_group\",\"timestamp\"], how=\"left\")\n",
    "feat_full_pred = grid_pred.merge(feat_pred_raw, on=[\"airport_group\",\"timestamp\"], how=\"left\")\n",
    "\n",
    "for df_ in (feat_full, feat_full_pred):\n",
    "    for c in [\"flights_cnt\",\"avg_duration\",\"max_duration\",\n",
    "              \"passenger_share\",\"cargo_share\",\"charter_share\",\"airline\", \"hour\"]:\n",
    "        if c in df_.columns:\n",
    "            if c == \"flights_cnt\":\n",
    "                df_[c] = df_[c].fillna(0).astype(int)\n",
    "            elif c == \"airline\":\n",
    "                df_[c] = df_[c].fillna(\"\")\n",
    "            else:\n",
    "                df_[c] = df_[c].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a38290",
   "metadata": {},
   "source": [
    "## Time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "90fd7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_full      = add_time_features(feat_full)\n",
    "feat_full_pred = add_time_features(feat_full_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f34a47a",
   "metadata": {},
   "source": [
    "## Next and previous hour flights count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b54097b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_full     = add_prev_next(feat_full)\n",
    "feat_full_pred = add_prev_next(feat_full_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2335d",
   "metadata": {},
   "source": [
    "## Vær"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c277ec",
   "metadata": {},
   "source": [
    "#### Add locations for airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "60080842",
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_locations_df = pd.read_csv(\"../data/raw_data/airports.csv\")\n",
    "airport_groups_df = pd.read_csv(\"../data/raw_data/airportgroups.csv\")\n",
    "\n",
    "airport_locations_df = airport_locations_df.merge(airport_groups_df, left_on=\"iata_code\", right_on=\"airport\")\n",
    "airport_locations_df = airport_locations_df.groupby(by = \"airport_group\")[[\"latitude_deg\", \"longitude_deg\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0770050a",
   "metadata": {},
   "source": [
    "#### Find weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34e3128d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     sensors[group] = resp\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m sensors.keys():\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     sensors[key] = \u001b[38;5;28msorted\u001b[39m(\u001b[43msensors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, key=\u001b[38;5;28;01mlambda\u001b[39;00m v: v[\u001b[33m\"\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mKeyError\u001b[39m: 'data'"
     ]
    }
   ],
   "source": [
    "## TODO: USE AIRPORT LOCATION ABOVE\n",
    "sensors = {}\n",
    "\n",
    "for (group, location) in airport_locations_df.iterrows():\n",
    "    endpoint = \"https://frost.met.no/sources/v0.jsonld\"\n",
    "    parameters = {\n",
    "        \"types\": \"SensorSystem\",\n",
    "        \"geometry\": f\"nearest(POINT({location[\"longitude_deg\"]} {location[\"latitude_deg\"]}))\"\n",
    "    }\n",
    "    r = requests.get(endpoint, parameters, auth=(os.getenv(\"FROST_ID\"),''))\n",
    "    resp = r.json()\n",
    "\n",
    "    sensors[group] = resp\n",
    "\n",
    "for key in sensors.keys():\n",
    "    sensors[key] = sorted(sensors[key][\"data\"], key=lambda v: v[\"distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1c3fcf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 66449\n",
      "2 / 66449\n",
      "3 / 66449\n",
      "4 / 66449\n",
      "5 / 66449\n",
      "6 / 66449\n",
      "7 / 66449\n",
      "8 / 66449\n",
      "9 / 66449\n",
      "10 / 66449\n",
      "11 / 66449\n",
      "12 / 66449\n",
      "13 / 66449\n",
      "14 / 66449\n",
      "15 / 66449\n",
      "16 / 66449\n",
      "17 / 66449\n",
      "18 / 66449\n",
      "19 / 66449\n",
      "20 / 66449\n",
      "21 / 66449\n",
      "22 / 66449\n",
      "23 / 66449\n",
      "24 / 66449\n",
      "25 / 66449\n",
      "26 / 66449\n",
      "27 / 66449\n",
      "28 / 66449\n",
      "29 / 66449\n",
      "30 / 66449\n",
      "31 / 66449\n",
      "32 / 66449\n",
      "33 / 66449\n",
      "34 / 66449\n",
      "35 / 66449\n",
      "36 / 66449\n",
      "37 / 66449\n",
      "38 / 66449\n",
      "39 / 66449\n",
      "40 / 66449\n",
      "41 / 66449\n",
      "42 / 66449\n",
      "43 / 66449\n",
      "44 / 66449\n",
      "45 / 66449\n",
      "46 / 66449\n",
      "47 / 66449\n",
      "48 / 66449\n",
      "49 / 66449\n",
      "50 / 66449\n",
      "51 / 66449\n",
      "52 / 66449\n",
      "53 / 66449\n",
      "54 / 66449\n",
      "55 / 66449\n",
      "56 / 66449\n",
      "57 / 66449\n",
      "58 / 66449\n",
      "59 / 66449\n",
      "60 / 66449\n",
      "61 / 66449\n",
      "62 / 66449\n",
      "63 / 66449\n",
      "64 / 66449\n",
      "65 / 66449\n",
      "66 / 66449\n",
      "67 / 66449\n",
      "68 / 66449\n",
      "69 / 66449\n",
      "70 / 66449\n",
      "71 / 66449\n",
      "72 / 66449\n",
      "73 / 66449\n",
      "74 / 66449\n",
      "75 / 66449\n",
      "76 / 66449\n",
      "77 / 66449\n",
      "78 / 66449\n",
      "79 / 66449\n",
      "80 / 66449\n",
      "81 / 66449\n",
      "82 / 66449\n",
      "83 / 66449\n",
      "84 / 66449\n",
      "85 / 66449\n",
      "86 / 66449\n",
      "87 / 66449\n",
      "88 / 66449\n",
      "89 / 66449\n",
      "90 / 66449\n",
      "91 / 66449\n",
      "92 / 66449\n",
      "93 / 66449\n",
      "94 / 66449\n",
      "95 / 66449\n",
      "96 / 66449\n",
      "97 / 66449\n",
      "98 / 66449\n",
      "99 / 66449\n",
      "100 / 66449\n",
      "101 / 66449\n",
      "102 / 66449\n",
      "103 / 66449\n",
      "104 / 66449\n",
      "105 / 66449\n",
      "106 / 66449\n",
      "107 / 66449\n",
      "108 / 66449\n",
      "109 / 66449\n",
      "110 / 66449\n",
      "111 / 66449\n",
      "112 / 66449\n",
      "113 / 66449\n",
      "114 / 66449\n",
      "115 / 66449\n",
      "116 / 66449\n",
      "117 / 66449\n",
      "118 / 66449\n",
      "119 / 66449\n",
      "120 / 66449\n",
      "121 / 66449\n",
      "122 / 66449\n",
      "123 / 66449\n",
      "124 / 66449\n",
      "125 / 66449\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     16\u001b[39m endpoint = \u001b[33m'\u001b[39m\u001b[33mhttps://frost.met.no/observations/v0.jsonld\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     17\u001b[39m parameters = {\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msources\u001b[39m\u001b[33m'\u001b[39m: sensors[row[\u001b[33m\"\u001b[39m\u001b[33mairport_group\u001b[39m\u001b[33m\"\u001b[39m]][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     19\u001b[39m     \u001b[33m'\u001b[39m\u001b[33melements\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mmean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     20\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mreferencetime\u001b[39m\u001b[33m'\u001b[39m: key,\n\u001b[32m     21\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFROST_ID\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m     25\u001b[39m     json = r.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.13.7/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "weather = {}\n",
    "values = [None] * 465143\n",
    "\n",
    "count = 0\n",
    "\n",
    "for (i, row) in feat_full.iterrows():\n",
    "    key = row[\"timestamp\"].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    if (row[\"airport_group\"] != \"A\"):\n",
    "        continue\n",
    "\n",
    "    if weather.get(row[\"airport_group\"]) == None:\n",
    "        weather[row[\"airport_group\"]] = {}\n",
    "\n",
    "    if weather.get(row[\"airport_group\"]).get(key) == None:\n",
    "        endpoint = 'https://frost.met.no/observations/v0.jsonld'\n",
    "        parameters = {\n",
    "            'sources': sensors[row[\"airport_group\"]][0][\"id\"],\n",
    "            'elements': 'mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)',\n",
    "            'referencetime': key,\n",
    "        }\n",
    "        r = requests.get(endpoint, parameters, auth=(os.getenv(\"FROST_ID\"),''))\n",
    "    \n",
    "        if r.status_code == 200:\n",
    "            json = r.json()\n",
    "    \n",
    "            k = json['data'][0]['observations'][0]['elementId']\n",
    "            v = json['data'][0]['observations'][0]['value']\n",
    "            \n",
    "            weather[row[\"airport_group\"]][key] = float(v)\n",
    "            count += 1\n",
    "\n",
    "            print(f\"{count} / 66449\")\n",
    "        else:\n",
    "            weather[row[\"airport_group\"]][key] = float('nan')\n",
    "    \n",
    "    feat_full.at[i, \"weather\"] = weather.get(row[\"airport_group\"]).get(key)\n",
    "\n",
    "feat_full.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7376beb9",
   "metadata": {},
   "source": [
    "# Samle datasett + split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5eef58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429527, 20) (15120, 20) (20496, 20) (5026, 19)\n"
     ]
    }
   ],
   "source": [
    "dataset = hourly.merge(feat_full, on=[\"airport_group\", \"timestamp\"], how=\"left\").sort_values(\"timestamp\")\n",
    "\n",
    "pred= hourly_pred.merge(feat_full_pred,on=[\"airport_group\",\"timestamp\"], how=\"left\").sort_values(\"timestamp\")\n",
    "\n",
    "dataset[\"timestamp\"] = pd.to_datetime(dataset[\"timestamp\"])\n",
    "pred[\"timestamp\"]    = pd.to_datetime(pred[\"timestamp\"])\n",
    "\n",
    "CUTOFF_VAL  = pd.Timestamp(\"2025-01-01\")  \n",
    "CUTOFF_TEST = pd.Timestamp(\"2025-04-01\")\n",
    "\n",
    "train = dataset[dataset[\"timestamp\"] <  CUTOFF_VAL].copy()\n",
    "val   = dataset[(dataset[\"timestamp\"] >= CUTOFF_VAL) & \n",
    "                (dataset[\"timestamp\"] <  CUTOFF_TEST)].copy()\n",
    "test  = dataset[dataset[\"timestamp\"] >= CUTOFF_TEST].copy()\n",
    "\n",
    "\n",
    "\n",
    "print(train.shape, val.shape, test.shape, pred.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a49ef9f",
   "metadata": {},
   "source": [
    "# lagre mellomfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b64ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../data/processed_data/train.csv', index=False)\n",
    "val.to_csv('../data/processed_data/val.csv', index=False)\n",
    "test.to_csv('../data/processed_data/test.csv', index=False)\n",
    "pred.to_csv('../data/processed_data/predict_oct2025.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
