{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e03d5c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5c52389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "no_holidays = holidays.NO()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28e9c7",
   "metadata": {},
   "source": [
    "# Parametre & stier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d88b899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/raw_data/historical_flights.csv\"\n",
    "CUTOFF = \"2024-01-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775cdaa0",
   "metadata": {},
   "source": [
    "# Hjelpefunksjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d761742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flights(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df[\"cancelled\"] == 0].copy()\n",
    "    for col in [\"std\", \"sta\", \"atd\", \"ata\"]:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def handle_wrong_times(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['duration'] = df['sta'] - df['std']\n",
    "    df = df[df['duration'] >= pd.Timedelta(0)].copy()\n",
    "    df = df[df['duration'] <= pd.Timedelta(hours=10)].copy()\n",
    "    return df\n",
    "\n",
    "def make_intervals(df: pd.DataFrame, actual: bool = True) -> pd.DataFrame:\n",
    "    if actual:\n",
    "        dep = df.dropna(subset=[\"atd\"]).copy()\n",
    "        dep[\"start\"] = dep[\"atd\"] - pd.to_timedelta(15, \"m\")\n",
    "        dep[\"end\"]   = dep[\"atd\"] + pd.to_timedelta(8, \"m\")\n",
    "        dep[\"delay\"] = (dep[\"atd\"] - dep[\"std\"]).dt.total_seconds() / 60\n",
    "\n",
    "        arr = df.dropna(subset=[\"ata\"]).copy()\n",
    "        arr[\"start\"] = arr[\"ata\"] - pd.to_timedelta(16, \"m\")\n",
    "        arr[\"end\"]   = arr[\"ata\"] + pd.to_timedelta(5, \"m\")\n",
    "        arr[\"delay\"] = (arr[\"ata\"] - arr[\"sta\"]).dt.total_seconds() / 60\n",
    "    else:\n",
    "        dep = df.dropna(subset=[\"std\"]).copy()\n",
    "        dep[\"start\"] = dep[\"std\"] - pd.to_timedelta(15, \"m\")\n",
    "        dep[\"end\"]   = dep[\"std\"] + pd.to_timedelta(8, \"m\")\n",
    "        dep[\"delay\"] = 0\n",
    "\n",
    "        arr = df.dropna(subset=[\"sta\"]).copy()\n",
    "        arr[\"start\"] = arr[\"sta\"] - pd.to_timedelta(16, \"m\")\n",
    "        arr[\"end\"]   = arr[\"sta\"] + pd.to_timedelta(5, \"m\")\n",
    "        arr[\"delay\"] = 0  # <- FIX: delay på arrivals i scheduled\n",
    "\n",
    "    dep[\"airport_group\"] = dep[\"dep_airport_group\"]\n",
    "    dep[\"type\"] = \"departure\"\n",
    "    arr[\"airport_group\"] = arr[\"arr_airport_group\"]\n",
    "    arr[\"type\"] = \"arrival\"\n",
    "\n",
    "    intervals = pd.concat([dep, arr], ignore_index=True)\n",
    "    intervals = intervals.dropna(subset=[\"airport_group\"])\n",
    "    return intervals\n",
    "\n",
    "def expand_to_hours(intervals: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, row in intervals.iterrows():\n",
    "        hour_start = row[\"start\"].floor(\"h\")\n",
    "        hour_end = row[\"end\"].floor(\"h\")\n",
    "        hours = pd.date_range(hour_start, hour_end, freq=\"h\")\n",
    "        for h in hours:\n",
    "            rows.append({**row, \"hour\": h})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def hourly_overlap(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    hour = group[\"hour\"].iloc[0]\n",
    "    h_start, h_end = hour, hour + pd.Timedelta(hours=1)\n",
    "    events = []\n",
    "    for _, row in group.iterrows():\n",
    "        s = max(row[\"start\"], h_start)\n",
    "        e = min(row[\"end\"],   h_end)\n",
    "        if s < e:\n",
    "            events.append((s, +1))\n",
    "            events.append((e, -1))\n",
    "    events.sort()\n",
    "    active = 0\n",
    "    for _, d in events:\n",
    "        active += d\n",
    "        if active > 1:\n",
    "            return pd.DataFrame([{\"airport_group\": group[\"airport_group\"].iloc[0], \"hour\": hour, \"target\": 1}])\n",
    "    return pd.DataFrame([{\"airport_group\": group[\"airport_group\"].iloc[0], \"hour\": hour, \"target\": 0}])\n",
    "\n",
    "def make_hourly_features(intervals_actual: pd.DataFrame) -> pd.DataFrame:\n",
    "    intervals_actual = intervals_actual.copy()\n",
    "    intervals_actual[\"duration_min\"] = ((intervals_actual[\"sta\"] - intervals_actual[\"std\"]).dt.total_seconds() / 60)\n",
    "\n",
    "    feats = intervals_actual.groupby([\"airport_group\", \"hour\"]).agg(\n",
    "        flights_cnt     = (\"flight_id\", \"count\"),\n",
    "        avg_duration    = (\"duration_min\", \"mean\"),\n",
    "        max_duration    = (\"duration_min\", \"max\"),\n",
    "        avg_delay       = (\"delay\", \"mean\"),\n",
    "        max_delay       = (\"delay\", \"max\"),\n",
    "        passenger_share = (\"service_type\", lambda x: (x == \"J\").mean()),\n",
    "        cargo_share     = (\"service_type\", lambda x: (x == \"P\").mean()),\n",
    "        charter_share   = (\"service_type\", lambda x: (x == \"C\").mean()),\n",
    "    ).reset_index()\n",
    "\n",
    "    feats[\"dow\"]     = feats[\"hour\"].dt.dayofweek\n",
    "    feats[\"holiday\"] = feats[\"hour\"].apply(lambda x: x.date() in no_holidays)\n",
    "    feats[\"month\"]   = feats[\"hour\"].dt.month\n",
    "    feats[\"hournum\"] = feats[\"hour\"].dt.hour\n",
    "    feats[\"weekend\"] = (feats[\"dow\"] >= 5).astype(int)\n",
    "\n",
    "    feats = feats.sort_values([\"airport_group\", \"hour\"])\n",
    "    feats[\"flights_cnt_prev\"] = feats.groupby(\"airport_group\")[\"flights_cnt\"].shift(1)\n",
    "    feats[\"flights_cnt_next\"] = feats.groupby(\"airport_group\")[\"flights_cnt\"].shift(-1)\n",
    "    feats[[\"flights_cnt_prev\", \"flights_cnt_next\"]] = feats[[\"flights_cnt_prev\", \"flights_cnt_next\"]].fillna(0).astype(int)\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bbc7c",
   "metadata": {},
   "source": [
    "# Last rådata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d4c8c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_id</th>\n",
       "      <th>dep_airport</th>\n",
       "      <th>dep_airport_group</th>\n",
       "      <th>arr_airport</th>\n",
       "      <th>arr_airport_group</th>\n",
       "      <th>service_type</th>\n",
       "      <th>std</th>\n",
       "      <th>sta</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>atd</th>\n",
       "      <th>ata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WF149</td>\n",
       "      <td>HOV</td>\n",
       "      <td>B</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-01-02 16:40:00</td>\n",
       "      <td>2018-01-02 17:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-01-02 18:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WF722</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MJF</td>\n",
       "      <td>D</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-01-28 13:04:00</td>\n",
       "      <td>2018-01-28 14:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WF188</td>\n",
       "      <td>FDE</td>\n",
       "      <td>A</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-04-07 07:10:00</td>\n",
       "      <td>2018-04-07 08:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-04-07 07:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WF176</td>\n",
       "      <td>HOV</td>\n",
       "      <td>B</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-04-07 11:00:00</td>\n",
       "      <td>2018-04-07 12:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-04-07 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WF148</td>\n",
       "      <td>HOV</td>\n",
       "      <td>B</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-04-30 08:25:00</td>\n",
       "      <td>2018-04-30 09:26:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-04-30 09:36:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flight_id dep_airport dep_airport_group arr_airport arr_airport_group  \\\n",
       "0     WF149         HOV                 B         OSL               NaN   \n",
       "1     WF722         OSL               NaN         MJF                 D   \n",
       "2     WF188         FDE                 A         OSL               NaN   \n",
       "3     WF176         HOV                 B         OSL               NaN   \n",
       "4     WF148         HOV                 B         OSL               NaN   \n",
       "\n",
       "  service_type                 std                 sta  cancelled atd  \\\n",
       "0            J 2018-01-02 16:40:00 2018-01-02 17:15:00          0 NaT   \n",
       "1            J 2018-01-28 13:04:00 2018-01-28 14:50:00          0 NaT   \n",
       "2            J 2018-04-07 07:10:00 2018-04-07 08:10:00          0 NaT   \n",
       "3            J 2018-04-07 11:00:00 2018-04-07 12:05:00          0 NaT   \n",
       "4            J 2018-04-30 08:25:00 2018-04-30 09:26:00          0 NaT   \n",
       "\n",
       "                  ata  \n",
       "0 2018-01-02 18:53:00  \n",
       "1                 NaT  \n",
       "2 2018-04-07 07:55:00  \n",
       "3 2018-04-07 12:00:00  \n",
       "4 2018-04-30 09:36:00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = load_flights(DATA_PATH)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348ce544",
   "metadata": {},
   "source": [
    "# Rens og filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f02755bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399341,\n",
       " flight_id            0.000\n",
       " dep_airport          0.000\n",
       " arr_airport          0.000\n",
       " service_type         0.000\n",
       " std                  0.000\n",
       " sta                  0.000\n",
       " cancelled            0.000\n",
       " duration             0.000\n",
       " atd                  0.013\n",
       " ata                  0.015\n",
       " dep_airport_group    0.433\n",
       " arr_airport_group    0.434\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = handle_wrong_times(df_raw)\n",
    "len(df), df.isna().mean().round(3).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5873f406",
   "metadata": {},
   "source": [
    "# Intervaller (actual) + hourly overlap (actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4cd48b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m intervals_actual \u001b[38;5;241m=\u001b[39m make_intervals(df, actual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m intervals_actual_expanded \u001b[38;5;241m=\u001b[39m expand_to_hours(intervals_actual)\n\u001b[1;32m      4\u001b[0m intervals_actual_expanded\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      6\u001b[0m hourly_actual \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      7\u001b[0m     intervals_actual_expanded\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mairport_group\u001b[39m\u001b[38;5;124m\"\u001b[39m, group_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mapply(hourly_overlap)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_actual\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     11\u001b[0m )\n",
      "Cell \u001b[0;32mIn[15], line 49\u001b[0m, in \u001b[0;36mexpand_to_hours\u001b[0;34m(intervals)\u001b[0m\n\u001b[1;32m     47\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m intervals\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 49\u001b[0m     hour_start \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     hour_end \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m     hours \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(hour_start, hour_end, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32mtimestamps.pyx:2089\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.floor\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimestamps.pyx:1876\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp._round\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32moffsets.pyx:4937\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.to_offset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimedeltas.pyx:1912\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.Timedelta.__new__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimedeltas.pyx:969\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas._timedelta_from_value_and_reso\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "intervals_actual = make_intervals(df, actual=True)\n",
    "\n",
    "intervals_actual_expanded = expand_to_hours(intervals_actual)\n",
    "intervals_actual_expanded.head()\n",
    "\n",
    "hourly_actual = (\n",
    "    intervals_actual_expanded\n",
    "    .groupby(\"airport_group\", group_keys=False)\n",
    "    .apply(hourly_overlap)\n",
    "    .rename(columns={\"target\": \"target_actual\"})\n",
    ")\n",
    "hourly_actual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796bc6bc",
   "metadata": {},
   "source": [
    "# Intervaller (scheduled) + hourly overlap (scheduled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bece8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_sched = make_intervals(df, actual=False)\n",
    "intervals_sched_expanded = expand_to_hours(intervals_sched)\n",
    "\n",
    "hourly_sched = (\n",
    "    intervals_sched_expanded\n",
    "    .groupby(\"airport_group\", group_keys=False)\n",
    "    .apply(hourly_overlap)\n",
    "    .rename(columns={\"target\": \"target_sched\"})\n",
    ")\n",
    "hourly_sched.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2d5dd",
   "metadata": {},
   "source": [
    "# Merge targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = hourly_actual.merge(hourly_sched, on=[\"airport_group\",\"hour\"], how=\"left\")\n",
    "hourly[\"target_sched\"] = hourly[\"target_sched\"].fillna(0).astype(int)\n",
    "hourly[\"hour\"] = pd.to_datetime(hourly[\"hour\"])\n",
    "hourly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b794ae0e",
   "metadata": {},
   "source": [
    "# Feature-agg (actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec75601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_features = make_hourly_features(intervals_actual_expanded.copy())\n",
    "hourly_features[\"hour\"] = pd.to_datetime(hourly_features[\"hour\"])\n",
    "hourly_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7376beb9",
   "metadata": {},
   "source": [
    "# Samle datasett + split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eef58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = hourly.merge(hourly_features, on=[\"airport_group\", \"hour\"], how=\"left\").sort_values(\"hour\")\n",
    "train = dataset[dataset[\"hour\"] < CUTOFF]\n",
    "val   = dataset[dataset[\"hour\"] >= CUTOFF]\n",
    "\n",
    "train.shape, val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a49ef9f",
   "metadata": {},
   "source": [
    "# lagre mellomfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/processed_data/train.csv', index=False)\n",
    "val.to_csv('data/processed_data/val.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF161",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
